{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Python/2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "father_path=\"/Users/leidelong/competition/Porto_Seguro_Safe_Driver_Prediction/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_url=father_path+\"train.csv\"\n",
    "train_raw=pd.read_csv(train_url)\n",
    "\n",
    "test_url=father_path+\"test.csv\"\n",
    "test_raw=pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    21694\n",
      "Name: target, dtype: int64\n",
      "0    573518\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#拆分数据集\n",
    "from sklearn.cross_validation import train_test_split  \n",
    "\n",
    "#标注正样本和负样本\n",
    "train_pos=train_raw[train_raw['target']==1]\n",
    "print (train_pos['target'].value_counts())\n",
    "train_neg=train_raw[train_raw['target']==0]\n",
    "print (train_neg['target'].value_counts())\n",
    "\n",
    "dtypes = train_raw.dtypes\n",
    "cols = train_raw.columns\n",
    "ty = dict(zip(cols,dtypes))\n",
    "\n",
    "#df转narray\n",
    "train_pos=np.array(train_pos)\n",
    "train_neg=np.array(train_neg)\n",
    "#数据集拆分\n",
    "train_pos_new,validation_pos_new = train_test_split(train_pos,  \n",
    "                                                   test_size = 0.2,  \n",
    "                                                   random_state = 0)  \n",
    "train_neg_new,validation_neg_new = train_test_split(train_neg,  \n",
    "                                                   test_size = 0.2,  \n",
    "                                                   random_state = 0)  \n",
    "#数据集拼接\n",
    "train_new=np.concatenate([train_pos_new,train_neg_new],axis=0) #在纵轴上合并\n",
    "\n",
    "validation_new=np.concatenate([validation_pos_new,validation_neg_new],axis=0) #在纵轴上合并\n",
    "\n",
    "\n",
    "#修改train、validation、test\n",
    "train_temp=pd.DataFrame(train_new)\n",
    "train_temp.columns=train_raw.columns\n",
    "train=train_temp\n",
    "train = train.astype(ty)\n",
    "\n",
    "validation_temp=pd.DataFrame(validation_new)\n",
    "validation_temp.columns=train_raw.columns\n",
    "validation=validation_temp\n",
    "validation = validation.astype(ty)\n",
    "\n",
    "test=test_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# test['target']=2\n",
    "test.insert(1,'target',2)\n",
    "\n",
    "train.insert(1,'tag','train')\n",
    "validation.insert(1,'tag','validation')\n",
    "test.insert(1,'tag','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata=pd.concat([train,validation,test]) #在纵轴上合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存储中间结果\n",
    "# train_validation_tag=pd.concat([train,validation])\n",
    "# train_validation_tag.to_csv(father_path+\"train_validation_tag.csv\",index=False)\n",
    "# print train_validation_tag.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建元数据dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in train.columns:\n",
    "    # Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    elif f == 'tag':\n",
    "        role = 'tag'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f in {'id','tag'}:\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == int:\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if f in {'id','tag'}:\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = train[f].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict = {\n",
    "        'varname': f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>level</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>nominal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input</td>\n",
       "      <td>binary</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input</td>\n",
       "      <td>interval</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input</td>\n",
       "      <td>nominal</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tag</td>\n",
       "      <td>nominal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>target</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     role     level  count\n",
       "0      id   nominal      1\n",
       "1   input    binary     17\n",
       "2   input  interval     10\n",
       "3   input   nominal     14\n",
       "4   input   ordinal     16\n",
       "5     tag   nominal      1\n",
       "6  target    binary      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'count' : meta.groupby(['role', 'level'])['role'].size()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'tag', u'target', u'ps_ind_01', u'ps_ind_02_cat', u'ps_ind_03',\n",
       "       u'ps_ind_04_cat', u'ps_ind_05_cat', u'ps_ind_06_bin', u'ps_ind_07_bin',\n",
       "       u'ps_ind_08_bin', u'ps_ind_09_bin', u'ps_ind_10_bin', u'ps_ind_11_bin',\n",
       "       u'ps_ind_12_bin', u'ps_ind_13_bin', u'ps_ind_14', u'ps_ind_15',\n",
       "       u'ps_ind_16_bin', u'ps_ind_17_bin', u'ps_ind_18_bin', u'ps_reg_01',\n",
       "       u'ps_reg_02', u'ps_reg_03', u'ps_car_01_cat', u'ps_car_02_cat',\n",
       "       u'ps_car_03_cat', u'ps_car_04_cat', u'ps_car_05_cat', u'ps_car_06_cat',\n",
       "       u'ps_car_07_cat', u'ps_car_08_cat', u'ps_car_09_cat', u'ps_car_10_cat',\n",
       "       u'ps_car_11_cat', u'ps_car_11', u'ps_car_12', u'ps_car_13',\n",
       "       u'ps_car_14', u'ps_car_15', u'ps_calc_01', u'ps_calc_02', u'ps_calc_03',\n",
       "       u'ps_calc_04', u'ps_calc_05', u'ps_calc_06', u'ps_calc_07',\n",
       "       u'ps_calc_08', u'ps_calc_09', u'ps_calc_10', u'ps_calc_11',\n",
       "       u'ps_calc_12', u'ps_calc_13', u'ps_calc_14', u'ps_calc_15_bin',\n",
       "       u'ps_calc_16_bin', u'ps_calc_17_bin', u'ps_calc_18_bin',\n",
       "       u'ps_calc_19_bin', u'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空值占比：\n",
      "('ps_ind_02_cat', ': 0.03515% ')\n",
      "('ps_ind_04_cat', ': 0.01532% ')\n",
      "('ps_ind_05_cat', ': 0.97572% ')\n",
      "('ps_reg_03', ': 18.10826% ')\n",
      "('ps_car_01_cat', ': 0.01794% ')\n",
      "('ps_car_02_cat', ': 0.00067% ')\n",
      "('ps_car_03_cat', ': 69.09426% ')\n",
      "('ps_car_05_cat', ': 44.81838% ')\n",
      "('ps_car_07_cat', ': 1.93679% ')\n",
      "('ps_car_09_cat', ': 0.09718% ')\n",
      "('ps_car_11', ': 0.00040% ')\n",
      "('ps_car_12', ': 0.00007% ')\n",
      "('ps_car_14', ': 7.15208% ')\n"
     ]
    }
   ],
   "source": [
    "target='target'\n",
    "IDcol = 'id'\n",
    "tag='tag'\n",
    "predictors = [x for x in alldata.columns if x not in [target, IDcol,tag]]\n",
    "\n",
    "print ('空值占比：')\n",
    "line_count=alldata['target'].count()\n",
    "for i in predictors :\n",
    "    nan_cnt=  line_count - alldata[i][alldata[i] != -1].count()\n",
    "    if nan_cnt!=0:\n",
    "        print (i,\": {:.5f}% \".format(nan_cnt/(line_count*1.0)*100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#baseline\n",
    "# new_train_validation=alldata[ (alldata['tag']=='train') | (alldata['tag']=='validation')]\n",
    "# new_train_validation.to_csv(father_path+\"train_extends_baseline.csv\",index=False)\n",
    "\n",
    "# print new_train_validation.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#剔除类别特征中空置率过高的特征，其他特征保留。保留原因参考（EDA中的分析内容）\n",
    "# vars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "# alldata.drop(vars_to_drop, inplace=True, axis=1)\n",
    "# meta.loc[(vars_to_drop),'keep'] = False  # Updating the meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#除了类别型特征，存在缺失的特征有 ps_reg_03、ps_car_11、ps_car_12、ps_car_14\n",
    "\n",
    "#均值填充\n",
    "mean_imp = Imputer(missing_values=-1, strategy='mean', axis=0)\n",
    "#最高频率填充\n",
    "mode_imp = Imputer(missing_values=-1, strategy='most_frequent', axis=0)\n",
    "#类别特征用-1表示，不做变化\n",
    "\n",
    "# alldata['ps_reg_03'] = mean_imp.fit_transform(alldata[['ps_reg_03']]).ravel()\n",
    "# alldata['ps_car_12'] = mean_imp.fit_transform(alldata[['ps_car_12']]).ravel()\n",
    "# alldata['ps_car_14'] = mean_imp.fit_transform(alldata[['ps_car_14']]).ravel()\n",
    "# alldata['ps_car_11'] = mode_imp.fit_transform(alldata[['ps_car_11']]).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>level</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>nominal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input</td>\n",
       "      <td>binary</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input</td>\n",
       "      <td>interval</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input</td>\n",
       "      <td>nominal</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tag</td>\n",
       "      <td>nominal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>target</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     role     level  count\n",
       "0      id   nominal      1\n",
       "1   input    binary     17\n",
       "2   input  interval     10\n",
       "3   input   nominal     14\n",
       "4   input   ordinal     16\n",
       "5     tag   nominal      1\n",
       "6  target    binary      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'count' : meta.groupby(['role', 'level'])['role'].size()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable ps_ind_02_cat has 5 distinct values\n",
      "Variable ps_ind_04_cat has 3 distinct values\n",
      "Variable ps_ind_05_cat has 8 distinct values\n",
      "Variable ps_car_01_cat has 13 distinct values\n",
      "Variable ps_car_02_cat has 3 distinct values\n",
      "Variable ps_car_03_cat has 3 distinct values\n",
      "Variable ps_car_04_cat has 10 distinct values\n",
      "Variable ps_car_05_cat has 3 distinct values\n",
      "Variable ps_car_06_cat has 18 distinct values\n",
      "Variable ps_car_07_cat has 3 distinct values\n",
      "Variable ps_car_08_cat has 2 distinct values\n",
      "Variable ps_car_09_cat has 6 distinct values\n",
      "Variable ps_car_10_cat has 3 distinct values\n",
      "Variable ps_car_11_cat has 104 distinct values\n"
     ]
    }
   ],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "\n",
    "for f in v:\n",
    "    dist_values = alldata[f].value_counts().shape[0]\n",
    "    print('Variable {} has {} distinct values'.format(f, dist_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #ps_car_11_cat类别过多，转为对应target均值的形式\n",
    "\n",
    "cat_perc = alldata[['ps_car_11_cat', 'target']].groupby(['ps_car_11_cat'],as_index=False).mean()\n",
    "cat_perc.rename(columns={'target': 'ps_car_11_cat_tm'}, inplace=True)\n",
    "alldata = pd.merge(alldata, cat_perc, how='inner', on='ps_car_11_cat')\n",
    "\n",
    "alldata.drop('ps_car_11_cat', axis=1, inplace=True)\n",
    "meta.loc['ps_car_11_cat','keep'] = False  # Updating the meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[(meta.level == 'nominal') & (meta.keep)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建哑变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dummification we have 60 variables in train\n",
      "After dummification we have 114 variables in train\n"
     ]
    }
   ],
   "source": [
    "# #暂时不处理\n",
    "\n",
    "\n",
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "print('Before dummification we have {} variables in train'.format(alldata.shape[1]))\n",
    "alldata = pd.get_dummies(alldata, columns=v, drop_first=True)\n",
    "print('After dummification we have {} variables in train'.format(alldata.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征组合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'ps_reg_01', u'ps_reg_02', u'ps_reg_03', u'ps_car_12', u'ps_car_13',\n",
      "       u'ps_car_14', u'ps_car_15', u'ps_calc_01', u'ps_calc_02',\n",
      "       u'ps_calc_03'],\n",
      "      dtype='object', name=u'varname')\n",
      "Before creating interactions we have 114 variables in train\n",
      "After creating interactions we have 179 variables in train\n"
     ]
    }
   ],
   "source": [
    "v = meta[(meta.level == 'interval') & (meta.keep)].index\n",
    "print v\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "interactions = pd.DataFrame(data=poly.fit_transform(alldata[v]), columns=poly.get_feature_names(v))\n",
    "# Merge the interaction variables to the train data\n",
    "print('Before creating interactions we have {} variables in train'.format(alldata.shape[1]))\n",
    "alldata = pd.concat([alldata, pd.DataFrame(data=interactions, columns=poly.get_feature_names(v))], axis=1)\n",
    "print('After creating interactions we have {} variables in train'.format(alldata.shape[1]))\n",
    "\n",
    "# alldata.id = alldata.id.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_validation=alldata[ (alldata['tag']=='train') | (alldata['tag']=='validation')]\n",
    "new_test=alldata[alldata['tag']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_validation.to_csv(father_path+\"train_extends.csv\",index=False)\n",
    "new_test.to_csv(father_path+\"test_extends.csv\",index=False)\n",
    "# alldata.to_csv(father_path+\"all_extends.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
